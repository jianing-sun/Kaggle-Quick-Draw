{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from glob import glob\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import nbimporter\n",
    "from DataParser import generateDf, getXYfromDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters defined here \"\"\"\n",
    "base_dir = '/Volumes/JS/QuickDraw'\n",
    "test_path = os.path.join(base_dir, '/test_simplified.csv')\n",
    "all_train_paths = glob(os.path.join(base_dir, 'train_simplified', '*.csv'))\n",
    "cols = ['countrycode', 'drawing', 'key_id', 'recognized', 'timestamp', 'word']\n",
    "# WaveNet parameters\n",
    "n_filters = 64\n",
    "kernel_size = 2\n",
    "dilation_depth = 8\n",
    "pool_size_1 = 4\n",
    "pool_size_2 = 8\n",
    "batch_size = 4096\n",
    "activation = 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words 340 => The Eiffel Tower, The Great Wall of China, The Mona Lisa, airplane, alarm clock, ambulance, angel, animal migration, ant, anvil, apple, arm, asparagus, axe, backpack, banana, bandage, barn, baseball, baseball bat, basket, basketball, bat, bathtub, beach, bear, beard, bed, bee, belt, bench, bicycle, binoculars, bird, birthday cake, blackberry, blueberry, book, boomerang, bottlecap, bowtie, bracelet, brain, bread, bridge, broccoli, broom, bucket, bulldozer, bus, bush, butterfly, cactus, cake, calculator, calendar, camel, camera, camouflage, campfire, candle, cannon, canoe, car, carrot, castle, cat, ceiling fan, cell phone, cello, chair, chandelier, church, circle, clarinet, clock, cloud, coffee cup, compass, computer, cookie, cooler, couch, cow, crab, crayon, crocodile, crown, cruise ship, cup, diamond, dishwasher, diving board, dog, dolphin, donut, door, dragon, dresser, drill, drums, duck, dumbbell, ear, elbow, elephant, envelope, eraser, eye, eyeglasses, face, fan, feather, fence, finger, fire hydrant, fireplace, firetruck, fish, flamingo, flashlight, flip flops, floor lamp, flower, flying saucer, foot, fork, frog, frying pan, garden, garden hose, giraffe, goatee, golf club, grapes, grass, guitar, hamburger, hammer, hand, harp, hat, headphones, hedgehog, helicopter, helmet, hexagon, hockey puck, hockey stick, horse, hospital, hot air balloon, hot dog, hot tub, hourglass, house, house plant, hurricane, ice cream, jacket, jail, kangaroo, key, keyboard, knee, ladder, lantern, laptop, leaf, leg, light bulb, lighthouse, lightning, line, lion, lipstick, lobster, lollipop, mailbox, map, marker, matches, megaphone, mermaid, microphone, microwave, monkey, moon, mosquito, motorbike, mountain, mouse, moustache, mouth, mug, mushroom, nail, necklace, nose, ocean, octagon, octopus, onion, oven, owl, paint can, paintbrush, palm tree, panda, pants, paper clip, parachute, parrot, passport, peanut, pear, peas, pencil, penguin, piano, pickup truck, picture frame, pig, pillow, pineapple, pizza, pliers, police car, pond, pool, popsicle, postcard, potato, power outlet, purse, rabbit, raccoon, radio, rain, rainbow, rake, remote control, rhinoceros, river, roller coaster, rollerskates, sailboat, sandwich, saw, saxophone, school bus, scissors, scorpion, screwdriver, sea turtle, see saw, shark, sheep, shoe, shorts, shovel, sink, skateboard, skull, skyscraper, sleeping bag, smiley face, snail, snake, snorkel, snowflake, snowman, soccer ball, sock, speedboat, spider, spoon, spreadsheet, square, squiggle, squirrel, stairs, star, steak, stereo, stethoscope, stitches, stop sign, stove, strawberry, streetlight, string bean, submarine, suitcase, sun, swan, sweater, swing set, sword, t-shirt, table, teapot, teddy-bear, telephone, television, tennis racquet, tent, tiger, toaster, toe, toilet, tooth, toothbrush, toothpaste, tornado, tractor, traffic light, train, tree, triangle, trombone, truck, trumpet, umbrella, underwear, van, vase, violin, washing machine, watermelon, waterslide, whale, wheel, windmill, wine bottle, wine glass, wristwatch, yoga, zebra, zigzag\n"
     ]
    }
   ],
   "source": [
    "train_df, valid_df, test_df, word_encoder = generateDf(n_train=750, n_valid=75, n_test=50, \n",
    "                                                       n_strokes=196, path=all_train_paths)\n",
    "x_train, y_train = getXYfromDf(train_df, word_encoder)\n",
    "x_valid, y_valid = getXYfromDf(valid_df, word_encoder)\n",
    "x_test, y_test = getXYfromDf(test_df, word_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, i):\n",
    "    tanh_out = layers.Conv1D(n_filters, \n",
    "                      kernel_size, \n",
    "                      dilation_rate = kernel_size**i, \n",
    "                      padding='causal', \n",
    "                      name='dilated_conv_%d_tanh' % (kernel_size ** i), \n",
    "                      activation='tanh'\n",
    "                      )(x)\n",
    "    sigm_out = layers.Conv1D(n_filters, \n",
    "                      kernel_size, \n",
    "                      dilation_rate = kernel_size**i, \n",
    "                      padding='causal', \n",
    "                      name='dilated_conv_%d_sigm' % (kernel_size ** i), \n",
    "                      activation='sigmoid'\n",
    "                      )(x)\n",
    "    z = layers.Multiply(name='gated_activation_%d' % (i))([tanh_out, sigm_out])\n",
    "    skip = layers.Conv1D(n_filters, 1, name='skip_%d'%(i))(z)\n",
    "    res = layers.Add(name='residual_block_%d' % (i))([skip, x])\n",
    "    return res, skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WaveNet(inputShape, outputShape):\n",
    "    stroke_input = layers.Input(shape=inputShape, name='featureInput')\n",
    "    x = layers.Conv1D(n_filters, kernel_size, dilation_rate=1, padding='causal',\n",
    "                      name='dilated_conv_1')(stroke_input)\n",
    "    skip_connections = []\n",
    "    for i in range(1, dilation_depth + 1):\n",
    "        x, skip = residual_block(x, i)\n",
    "        skip_connections.append(skip)\n",
    "    x = layers.Add(name='skip_connections')(skip_connections)\n",
    "#     x = layers.Activation('relu')(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "    x = layers.Conv1D(n_filters, pool_size_1, strides=1, padding='same',\n",
    "                     name='conv_5ms', activation='relu')(x)\n",
    "    x = layers.Conv1D(output_shape[0], pool_size_2, padding='same', activation='relu',\n",
    "                    name='conv_500ms')(x)\n",
    "    x = layers.Conv1D(output_shape[0], pool_size_2, padding='same', activation='relu', \n",
    "                      name='conv_500ms_target_shape')(x)\n",
    "    x = layers.AveragePooling1D(pool_size_2, padding='same',name = 'downsample_to_2Hz')(x)\n",
    "    x = layers.Conv1D(output_shape[0], (int) (input_shape[0] / (pool_size_1*pool_size_2)), \n",
    "                      padding='same', name='final_conv')(x)\n",
    "    x = layers.GlobalAveragePooling1D(name='final_pooling')(x)\n",
    "    x = layers.Activation(activation, name='final_activation')(x)\n",
    "    \n",
    "    model = Model(input=stroke_input, output=x)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "output_shape = y_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "featureInput (InputLayer)       (None, 196, 3)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_1 (Conv1D)         (None, 196, 64)      448         featureInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_2_tanh (Conv1D)    (None, 196, 64)      8256        dilated_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_2_sigm (Conv1D)    (None, 196, 64)      8256        dilated_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_1 (Multiply)   (None, 196, 64)      0           dilated_conv_2_tanh[0][0]        \n",
      "                                                                 dilated_conv_2_sigm[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "skip_1 (Conv1D)                 (None, 196, 64)      4160        gated_activation_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_1 (Add)          (None, 196, 64)      0           skip_1[0][0]                     \n",
      "                                                                 dilated_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_4_tanh (Conv1D)    (None, 196, 64)      8256        residual_block_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_4_sigm (Conv1D)    (None, 196, 64)      8256        residual_block_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_2 (Multiply)   (None, 196, 64)      0           dilated_conv_4_tanh[0][0]        \n",
      "                                                                 dilated_conv_4_sigm[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "skip_2 (Conv1D)                 (None, 196, 64)      4160        gated_activation_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_2 (Add)          (None, 196, 64)      0           skip_2[0][0]                     \n",
      "                                                                 residual_block_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_8_tanh (Conv1D)    (None, 196, 64)      8256        residual_block_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_8_sigm (Conv1D)    (None, 196, 64)      8256        residual_block_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_3 (Multiply)   (None, 196, 64)      0           dilated_conv_8_tanh[0][0]        \n",
      "                                                                 dilated_conv_8_sigm[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "skip_3 (Conv1D)                 (None, 196, 64)      4160        gated_activation_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_3 (Add)          (None, 196, 64)      0           skip_3[0][0]                     \n",
      "                                                                 residual_block_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_16_tanh (Conv1D)   (None, 196, 64)      8256        residual_block_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_16_sigm (Conv1D)   (None, 196, 64)      8256        residual_block_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_4 (Multiply)   (None, 196, 64)      0           dilated_conv_16_tanh[0][0]       \n",
      "                                                                 dilated_conv_16_sigm[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "skip_4 (Conv1D)                 (None, 196, 64)      4160        gated_activation_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_4 (Add)          (None, 196, 64)      0           skip_4[0][0]                     \n",
      "                                                                 residual_block_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_32_tanh (Conv1D)   (None, 196, 64)      8256        residual_block_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_32_sigm (Conv1D)   (None, 196, 64)      8256        residual_block_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_5 (Multiply)   (None, 196, 64)      0           dilated_conv_32_tanh[0][0]       \n",
      "                                                                 dilated_conv_32_sigm[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "skip_5 (Conv1D)                 (None, 196, 64)      4160        gated_activation_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_5 (Add)          (None, 196, 64)      0           skip_5[0][0]                     \n",
      "                                                                 residual_block_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_64_tanh (Conv1D)   (None, 196, 64)      8256        residual_block_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_64_sigm (Conv1D)   (None, 196, 64)      8256        residual_block_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_6 (Multiply)   (None, 196, 64)      0           dilated_conv_64_tanh[0][0]       \n",
      "                                                                 dilated_conv_64_sigm[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "skip_6 (Conv1D)                 (None, 196, 64)      4160        gated_activation_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_6 (Add)          (None, 196, 64)      0           skip_6[0][0]                     \n",
      "                                                                 residual_block_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_128_tanh (Conv1D)  (None, 196, 64)      8256        residual_block_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_128_sigm (Conv1D)  (None, 196, 64)      8256        residual_block_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_7 (Multiply)   (None, 196, 64)      0           dilated_conv_128_tanh[0][0]      \n",
      "                                                                 dilated_conv_128_sigm[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "skip_7 (Conv1D)                 (None, 196, 64)      4160        gated_activation_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_7 (Add)          (None, 196, 64)      0           skip_7[0][0]                     \n",
      "                                                                 residual_block_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_256_tanh (Conv1D)  (None, 196, 64)      8256        residual_block_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_256_sigm (Conv1D)  (None, 196, 64)      8256        residual_block_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_8 (Multiply)   (None, 196, 64)      0           dilated_conv_256_tanh[0][0]      \n",
      "                                                                 dilated_conv_256_sigm[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "skip_8 (Conv1D)                 (None, 196, 64)      4160        gated_activation_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "skip_connections (Add)          (None, 196, 64)      0           skip_1[0][0]                     \n",
      "                                                                 skip_2[0][0]                     \n",
      "                                                                 skip_3[0][0]                     \n",
      "                                                                 skip_4[0][0]                     \n",
      "                                                                 skip_5[0][0]                     \n",
      "                                                                 skip_6[0][0]                     \n",
      "                                                                 skip_7[0][0]                     \n",
      "                                                                 skip_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 196, 64)      0           skip_connections[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_5ms (Conv1D)               (None, 196, 64)      16448       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_500ms (Conv1D)             (None, 196, 340)     174420      conv_5ms[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_500ms_target_shape (Conv1D (None, 196, 340)     925140      conv_500ms[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "downsample_to_2Hz (AveragePooli (None, 25, 340)      0           conv_500ms_target_shape[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv1D)             (None, 25, 340)      693940      downsample_to_2Hz[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "final_pooling (GlobalAveragePoo (None, 340)          0           final_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "final_activation (Activation)   (None, 340)          0           final_pooling[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,975,772\n",
      "Trainable params: 1,975,772\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"fe..., outputs=Tensor(\"fi...)`\n"
     ]
    }
   ],
   "source": [
    "model = WaveNet(input_shape, output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(x,y): \n",
    "    return top_k_categorical_accuracy(x,y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    date = datetime.datetime.today().strftime('%H_%M_%m_%d')\n",
    "    weight_save_path = './model/stroke_wn_%s' % date + '.h5'\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(weight_save_path, monitor='val_loss',\n",
    "                                verbose=1, save_best_only=True, period=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.6, \n",
    "                                  patience=5, min_lr=1e-6, mode='auto')\n",
    "    early_stop = EarlyStopping(monitor'val_loss', mode='min', patience=5)\n",
    "    callback = [checkpoint, early, reduce_lr]\n",
    "    optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy', top_3_accuracy])\n",
    "    model.fit(x_train, y_train, \n",
    "              validation_data=(x_valid, y_valid),\n",
    "              batch_size=batch_size,\n",
    "              epochs=50\n",
    "              callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, weight_path):\n",
    "    model = model.load_weights(weight_path)\n",
    "    result = model.evaluate(x_test, y_test, batch_size=4096)\n",
    "    print('Accuracy: %2.1f%%, Top 3 Accuracy %2.1f%%' % (100*lstm_results[1], 100*lstm_results[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearnReport(model, weight_path):\n",
    "    model = model.load_weights(weight_path)\n",
    "    test_cat = np.argmax(y_test, 1)\n",
    "    pred_y = model.predict(x_test, batch_size = 4096)\n",
    "    pred_cat = np.argmax(pred_y, 1)\n",
    "    plt.matshow(confusion_matrix(test_cat, pred_cat))\n",
    "    print(classification_report(test_cat, pred_cat, \n",
    "                            target_names = [x for x in word_encoder.classes_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
