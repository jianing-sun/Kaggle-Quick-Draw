{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from DataParserForCNN.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nbimporter\n",
    "import numpy as np\n",
    "import sys\n",
    "import cv2\n",
    "from timeit import default_timer as timer\n",
    "from DataParserForCNN import read_full_df, read_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_array = read_class()\n",
    "# base_path = 'C:/Users/IML/Desktop/QuickDrawDataset/'\n",
    "base_path = '/Volumes/JS/QuickDraw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t load df   :  339/340                   zigzag   7 min 21 sec\n",
      "\n",
      "\t load valid_set split:  339/340                   zigzag  10 min 48 sec"
     ]
    }
   ],
   "source": [
    "full_df, train_id, valid_id = read_full_df(base_path, class_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawing_to_image(drawing, H, W):\n",
    "\n",
    "    point=[]\n",
    "    time =[]\n",
    "    \n",
    "#     coordinates = []\n",
    "    \n",
    "    for t,(x,y) in enumerate(drawing):\n",
    "        point.append(np.array((x,y),np.float32).T)\n",
    "        time.append(np.full(len(x),t))\n",
    "\n",
    "    point = np.concatenate(point).astype(np.float32)\n",
    "    time  = np.concatenate(time).astype(np.int32)\n",
    "\n",
    "    image  = np.full((H,W,3),0,np.uint8)\n",
    "    x_max = point[:,0].max()\n",
    "    x_min = point[:,0].min()\n",
    "    y_max = point[:,1].max()\n",
    "    y_min = point[:,1].min()\n",
    "    w = x_max-x_min\n",
    "    h = y_max-y_min\n",
    "    #print(w,h)\n",
    "\n",
    "    s = max(w,h)\n",
    "    norm_point = (point-[x_min,y_min])/s\n",
    "    norm_point = (norm_point-[w/s*0.5,h/s*0.5])*max(W,H)*0.85\n",
    "    norm_point = np.floor(norm_point + [W/2,H/2]).astype(np.int32)\n",
    "\n",
    "    T = time.max()+1\n",
    "    for t in range(T):\n",
    "        p = norm_point[time==t]\n",
    "        x,y = p.T\n",
    "        image[y,x]=255\n",
    "        N = len(p)\n",
    "        for i in range(N-1):\n",
    "            x0,y0 = p[i]\n",
    "            x1,y1 = p[i+1]\n",
    "            cv2.line(image,(x0,y0),(x1,y1),(255,255,255),1,cv2.LINE_AA)\n",
    "\n",
    "#     return np.transpose(image, (2,0,1))\n",
    "    return image\n",
    "\n",
    "\n",
    "def null_augment(drawing, label, index):\n",
    "#     cache = Struct(drawing = drawing.copy(), label = label, index=index)\n",
    "    image = drawing_to_image(drawing, 64, 64)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.parallel.data_parallel import data_parallel\n",
    "from torch.utils.data.sampler import *\n",
    "from model import shake_drop_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(object):\n",
    "    def __init__(self):\n",
    "        self.terminal = sys.stdout  #stdout\n",
    "        self.file = None\n",
    "\n",
    "    def open(self, file, mode=None):\n",
    "        if mode is None: mode ='w'\n",
    "        self.file = open(file, mode)\n",
    "\n",
    "    def write(self, message, is_terminal=1, is_file=1):\n",
    "        if '\\r' in message: is_file=0\n",
    "\n",
    "        if is_terminal == 1:\n",
    "            self.terminal.write(message)\n",
    "            self.terminal.flush()\n",
    "            #time.sleep(1)\n",
    "\n",
    "        if is_file == 1:\n",
    "            self.file.write(message)\n",
    "            self.file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoodleDataset(Dataset):\n",
    "\n",
    "    def __init__(self, \n",
    "                 full_df, \n",
    "                 datasplit_id,\n",
    "                 shuffle=False,\n",
    "                 augment=null_augment, \n",
    "                 mode='simplified'):\n",
    "        super(DoodleDataset, self).__init__()\n",
    "        assert mode in ['simplified', 'raw']\n",
    "\n",
    "        self.datasplit_id = datasplit_id\n",
    "        self.augment = augment\n",
    "        self.mode = mode\n",
    "\n",
    "        self.df = full_df\n",
    "        self.id = datasplit_id\n",
    "        \n",
    "         ### shuffle                    \n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.datasplit_id)\n",
    "        print('\\n')\n",
    "\n",
    "    def __str__(self):\n",
    "        N = len(self.id)\n",
    "        string = '' \\\n",
    "                 + '\\tmode         = %s\\n' % self.mode \\\n",
    "                 + '\\tlen(self.id) = %d\\n' % N \\\n",
    "                 + '\\n'\n",
    "        return string\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "#         if self.mode == 'train':\n",
    "        label, drawing_id, key_id = self.id[index]\n",
    "        drawing = self.df[label]['drawing'][drawing_id]\n",
    "        drawing = eval(drawing)\n",
    "\n",
    "#         if self.mode == 'test':\n",
    "#             label = None\n",
    "#             drawing = self.df['drawing'][index]\n",
    "#             drawing = eval(drawing)\n",
    "\n",
    "        return self.augment(drawing, label, index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_collate(batch):\n",
    "    batch_size = len(batch)\n",
    "#     cache = []\n",
    "    input = []\n",
    "    truth = []\n",
    "    for b in range(batch_size):\n",
    "        input.append(batch[b][0])\n",
    "        truth.append(batch[b][1])\n",
    "#         cache.append(batch[b][2])\n",
    "\n",
    "    input = np.array(input).transpose(0, 3, 1, 2)\n",
    "    input = torch.from_numpy(input).float()\n",
    "\n",
    "    if truth[0] is not None:\n",
    "        truth = np.array(truth)\n",
    "        truth = torch.from_numpy(truth).long()\n",
    "\n",
    "    return input, truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DoodleDataset(full_df, train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset,\n",
    "                          sampler=RandomSampler(train_dataset),\n",
    "                          batch_size=128,\n",
    "                          drop_last=True,\n",
    "                          num_workers=2,\n",
    "                          collate_fn=null_collate)\n",
    "\n",
    "valid_dataset = DoodleDataset(full_df, valid_id, null_augment)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset,\n",
    "#                           sampler=RandomSampler(valid_dataset),\n",
    "                          batch_size=128,\n",
    "                          drop_last=False,\n",
    "                          num_workers=2,\n",
    "                          collate_fn=null_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49680379\n",
      "27200\n",
      "388127\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(valid_dataset))\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_dataset[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [START 2018-11-03_15-57-19] ----------------------------------------------------------------\n",
      "\n",
      "\tout_dir      = ./results/\n",
      "\n",
      "\t<additional comments>\n",
      "\t  ... shakedrop on resnet50  ... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "out_dir = './results/'\n",
    "\n",
    "IDENTIFIER = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "log = Logger()\n",
    "log.open(out_dir + '/log.train.txt', mode='a')\n",
    "log.write('\\n--- [START %s] %s\\n\\n' % (IDENTIFIER, '-' * 64))\n",
    "log.write('\\tout_dir      = %s\\n' % out_dir)\n",
    "log.write('\\n')\n",
    "log.write('\\t<additional comments>\\n')\n",
    "log.write('\\t  ... shakedrop on resnet50  ... \\n')\n",
    "log.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** dataset setting **\n",
      "batch_size = 1024\n",
      "train_dataset : \n",
      "\tmode         = simplified\n",
      "\tlen(self.id) = 49680379\n",
      "\n",
      "\n",
      "valid_dataset : \n",
      "\tmode         = simplified\n",
      "\tlen(self.id) = 27200\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.write('** dataset setting **\\n')\n",
    "batch_size = 128\n",
    "log.write('batch_size = %d\\n' % (batch_size))\n",
    "log.write('train_dataset : \\n%s\\n' % (train_dataset))\n",
    "log.write('valid_dataset : \\n%s\\n' % (valid_dataset))\n",
    "log.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log.write('** net setting **\\n')\n",
    "net = shake_drop_net()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = net.to(device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    \n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShakeDropNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(16, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(20, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (bn1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(23, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (bn1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(26, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (bn1): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(30, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(34, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (bn1): BatchNorm2d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(34, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(37, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (6): BasicBlock(\n",
       "      (bn1): BatchNorm2d(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(37, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (7): BasicBlock(\n",
       "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(40, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (bn1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(44, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(48, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(51, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (bn1): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(51, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (bn1): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(54, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(58, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (bn1): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(62, 65, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(65, 65, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (6): BasicBlock(\n",
       "      (bn1): BatchNorm2d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(65, 68, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(68, 68, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (7): BasicBlock(\n",
       "      (bn1): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(68, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(72, 76, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(76, 76, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (bn1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(76, 79, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(79, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(79, 79, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(79, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (bn1): BatchNorm2d(79, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(79, 82, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(82, 82, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (bn1): BatchNorm2d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(82, 86, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(86, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(86, 86, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(86, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (bn1): BatchNorm2d(86, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(86, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (bn1): BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(90, 93, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(93, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(93, 93, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(93, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (6): BasicBlock(\n",
       "      (bn1): BatchNorm2d(93, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(93, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (7): BasicBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(96, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (bn_final): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_final): ReLU(inplace)\n",
       "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "  (fc): Linear(in_features=100, out_features=340, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-4,\n",
    "                      momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(logit, truth, is_average=True):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prob = F.softmax(logit, 1)\n",
    "        value, top = prob.topk(3, dim=1, largest=True, sorted=True)\n",
    "        correct = top.eq(truth.view(-1, 1).expand_as(top))\n",
    "\n",
    "        if is_average==True:\n",
    "            # top-3 accuracy\n",
    "            correct = correct.float().sum(0, keepdim=False)\n",
    "            correct = correct/len(truth)\n",
    "\n",
    "            top = [correct[0], correct[0]+correct[1], correct[0]+correct[1]+correct[2]]\n",
    "            precision = correct[0]/1 + correct[1]/2 + correct[2]/3\n",
    "            return precision, top\n",
    "\n",
    "        else:\n",
    "            return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    net.train()\n",
    "    train_loss = np.zeros(6, np.float32)\n",
    "    valid_loss = np.zeros(6, np.float32)\n",
    "    batch_loss = np.zeros(6, np.float32)\n",
    "    num_iters = 300 * 1000\n",
    "    iter = 0\n",
    "    iter_save_interval = 2000\n",
    "    iter_smooth = 20\n",
    "    iter_valid = 100\n",
    "    start_iter = 0\n",
    "    iter_save = [0, num_iters - 1] + list(range(0, num_iters, iter_save_interval))  # 1*1000\n",
    "    start_epoch = 0\n",
    "    rate = 0\n",
    "    i = 0\n",
    "\n",
    "    start = timer()\n",
    "    while iter < num_iters:\n",
    "        sum_train_loss = np.zeros(6, np.float32)\n",
    "        sum = 0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        for inputs, truth in train_loader:\n",
    "\n",
    "            len_train_dataset = len(train_dataset)\n",
    "            batch_size = 1024\n",
    "            iter = i + start_iter\n",
    "            epoch = (iter - start_iter) * batch_size / len_train_dataset + start_epoch\n",
    "            num_samples = epoch * len_train_dataset\n",
    "\n",
    "#             if (iter % iter_valid == 0) and (iter != 0):\n",
    "#                 net.set_mode('valid')\n",
    "#                 valid_loss = do_valid(net, valid_loader, criterion)\n",
    "#                 net.set_mode('train')\n",
    "\n",
    "#                 asterisk = '*' if iter in iter_save else ' '\n",
    "#                 ##--------\n",
    "\n",
    "#                 print('\\r', end='', flush=True)\n",
    "#                 log.write('%0.4f %5.1f %6.1f | %0.3f  %0.3f  %0.3f  (%0.3f)%s  | %0.3f  %0.3f  %0.3f  (%0.3f)  | %s' % ( \\\n",
    "#                     rate, iter / 1000, epoch,\n",
    "#                     valid_loss[0], valid_loss[1], valid_loss[2], valid_loss[3], asterisk,\n",
    "#                     train_loss[0], train_loss[1], train_loss[2], train_loss[3],\n",
    "#                     time_to_str((timer() - start), 'min'))\n",
    "#                           )\n",
    "#                 log.write('\\n')\n",
    "#                 time.sleep(0.01)\n",
    "\n",
    "            if iter in iter_save:\n",
    "                torch.save(net.state_dict(), out_dir + 'checkpoint/%08d_model.pth' % (iter))\n",
    "                torch.save({\n",
    "                    # 'optimizer': optimizer.state_dict(),\n",
    "                    'iter': iter,\n",
    "                    'epoch': epoch,\n",
    "                }, out_dir + 'checkpoint/%08d_optimizer.pth' % (iter))\n",
    "\n",
    "            # learning rate schduler -------------\n",
    "#             lr = schduler(iter)\n",
    "#             if lr < 0: \n",
    "#                 break\n",
    "#             adjust_learning_rate(optimizer, lr)\n",
    "#             rate = get_learning_rate(optimizer)\n",
    "\n",
    "            # one iteration update  -------------\n",
    "            # net.set_mode('train',is_freeze_bn=True)\n",
    "\n",
    "#             input = input.cuda()\n",
    "#             truth = truth.cuda()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(output, truth)\n",
    "            precision, top = metric(output, truth)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # print statistics  ------------\n",
    "            batch_loss[:4] = np.array((loss.item(), top[0].item(), top[2].item(), precision.item(),))\n",
    "            sum_train_loss += batch_loss\n",
    "            sum += 1\n",
    "            if iter % iter_smooth == 0:\n",
    "                train_loss = sum_train_loss / sum\n",
    "                sum_train_loss = np.zeros(6, np.float32)\n",
    "                sum = 0\n",
    "\n",
    "            print('\\r', end='', flush=True)\n",
    "            print('%0.4f %5.1f %6.1f | %0.3f  %0.3f  %0.3f  (%0.3f)%s  | %0.3f  %0.3f  %0.3f  (%0.3f)  | %s' % ( \\\n",
    "                rate, iter / 1000, epoch,\n",
    "                valid_loss[0], valid_loss[1], valid_loss[2], valid_loss[3], ' ',\n",
    "                batch_loss[0], batch_loss[1], batch_loss[2], batch_loss[3],\n",
    "                time_to_str((timer() - start), 'min'))\n",
    "                  , end='', flush=True)\n",
    "            i = i + 1\n",
    "\n",
    "    if 1:  # save last\n",
    "        torch.save(net.state_dict(), out_dir + 'checkpoint/%d_model.pth' % (i))\n",
    "        torch.save({\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'iter': i,\n",
    "            'epoch': epoch,\n",
    "        }, out_dir + 'checkpoint/%d_optimizer.pth' % (i))\n",
    "\n",
    "    log.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-63f33e1a627e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(epoch):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        print(np.array(inputs).shape)\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        print(outputs)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('epoch : {} [{}/{}]| loss: {:.3f} | acc: {:.3f}'.format(epoch, batch_idx,\n",
    "                                                                          len(train_loader),\n",
    "                                                                          train_loss / (batch_idx + 1),\n",
    "                                                                          100. * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "run_train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
