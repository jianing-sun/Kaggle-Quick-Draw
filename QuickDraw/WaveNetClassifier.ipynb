{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from DataParser.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "from glob import glob\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import nbimporter\n",
    "from DataParser import generateDf, getXYfromDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0',\n",
       " '/job:localhost/replica:0/task:0/device:GPU:1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters defined here \"\"\"\n",
    "base_dir = './dataset'\n",
    "test_path = os.path.join(base_dir, '/test_simplified.csv')\n",
    "all_train_paths = glob(os.path.join(base_dir, 'train_simplified', '*.csv'))\n",
    "cols = ['countrycode', 'drawing', 'key_id', 'recognized', 'timestamp', 'word']\n",
    "# WaveNet parameters\n",
    "n_filters = 64\n",
    "kernel_size = 2\n",
    "dilation_depth = 8\n",
    "pool_size_1 = 4\n",
    "pool_size_2 = 8\n",
    "batch_size = 2048\n",
    "activation = 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df, valid_df, test_df, word_encoder = generateDf(n_train=750, n_valid=75, n_test=50, n_strokes=196, path=all_train_paths)\n",
    "x_train, y_train = getXYfromDf(train_df, word_encoder)\n",
    "x_valid, y_valid = getXYfromDf(valid_df, word_encoder)\n",
    "x_test, y_test = getXYfromDf(test_df, word_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, i):\n",
    "    tanh_out = layers.Conv1D(n_filters, \n",
    "                      kernel_size, \n",
    "                      dilation_rate = kernel_size**i, \n",
    "                      padding='causal', \n",
    "                      name='dilated_conv_%d_tanh' % (kernel_size ** i), \n",
    "                      activation='tanh'\n",
    "                      )(x)\n",
    "    sigm_out = layers.Conv1D(n_filters, \n",
    "                      kernel_size, \n",
    "                      dilation_rate = kernel_size**i, \n",
    "                      padding='causal', \n",
    "                      name='dilated_conv_%d_sigm' % (kernel_size ** i), \n",
    "                      activation='sigmoid'\n",
    "                      )(x)\n",
    "    z = layers.Multiply(name='gated_activation_%d' % (i))([tanh_out, sigm_out])\n",
    "    skip = layers.Conv1D(n_filters, 1, name='skip_%d'%(i))(z)\n",
    "    res = layers.Add(name='residual_block_%d' % (i))([skip, x])\n",
    "    return res, skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WaveNet(inputShape, outputShape):\n",
    "    stroke_input = layers.Input(shape=inputShape, name='featureInput')\n",
    "    x = layers.Conv1D(n_filters, kernel_size, dilation_rate=1, padding='causal',\n",
    "                      name='dilated_conv_1')(stroke_input)\n",
    "    skip_connections = []\n",
    "    for i in range(1, dilation_depth + 1):\n",
    "        x, skip = residual_block(x, i)\n",
    "        skip_connections.append(skip)\n",
    "    x = layers.Add(name='skip_connections')(skip_connections)\n",
    "    x = layers.Activation('relu')(x)\n",
    "#     x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "    x = layers.Conv1D(n_filters, pool_size_1, strides=1, padding='same',\n",
    "                     name='conv_5ms', activation='relu')(x)\n",
    "    x = layers.Conv1D(output_shape[0], pool_size_2, padding='same', activation='relu',\n",
    "                    name='conv_500ms')(x)\n",
    "    x = layers.Conv1D(output_shape[0], pool_size_2, padding='same', activation='relu', \n",
    "                      name='conv_500ms_target_shape')(x)\n",
    "    x = layers.AveragePooling1D(pool_size_2, padding='same',name = 'downsample_to_2Hz')(x)\n",
    "    x = layers.Conv1D(output_shape[0], (int) (input_shape[0] / (pool_size_1*pool_size_2)), \n",
    "                      padding='same', name='final_conv')(x)\n",
    "    x = layers.GlobalAveragePooling1D(name='final_pooling')(x)\n",
    "    x = layers.Activation(activation, name='final_activation')(x)\n",
    "    \n",
    "    model = Model(input=stroke_input, output=x)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "output_shape = y_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "featureInput (InputLayer)       (None, 196, 3)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_1 (Conv1D)         (None, 196, 64)      448         featureInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_2_tanh (Conv1D)    (None, 196, 64)      8256        dilated_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_2_sigm (Conv1D)    (None, 196, 64)      8256        dilated_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_1 (Multiply)   (None, 196, 64)      0           dilated_conv_2_tanh[0][0]        \n",
      "                                                                 dilated_conv_2_sigm[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "skip_1 (Conv1D)                 (None, 196, 64)      4160        gated_activation_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_1 (Add)          (None, 196, 64)      0           skip_1[0][0]                     \n",
      "                                                                 dilated_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_4_tanh (Conv1D)    (None, 196, 64)      8256        residual_block_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_4_sigm (Conv1D)    (None, 196, 64)      8256        residual_block_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_2 (Multiply)   (None, 196, 64)      0           dilated_conv_4_tanh[0][0]        \n",
      "                                                                 dilated_conv_4_sigm[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "skip_2 (Conv1D)                 (None, 196, 64)      4160        gated_activation_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_2 (Add)          (None, 196, 64)      0           skip_2[0][0]                     \n",
      "                                                                 residual_block_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_8_tanh (Conv1D)    (None, 196, 64)      8256        residual_block_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_8_sigm (Conv1D)    (None, 196, 64)      8256        residual_block_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_3 (Multiply)   (None, 196, 64)      0           dilated_conv_8_tanh[0][0]        \n",
      "                                                                 dilated_conv_8_sigm[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "skip_3 (Conv1D)                 (None, 196, 64)      4160        gated_activation_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_3 (Add)          (None, 196, 64)      0           skip_3[0][0]                     \n",
      "                                                                 residual_block_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_16_tanh (Conv1D)   (None, 196, 64)      8256        residual_block_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_16_sigm (Conv1D)   (None, 196, 64)      8256        residual_block_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_4 (Multiply)   (None, 196, 64)      0           dilated_conv_16_tanh[0][0]       \n",
      "                                                                 dilated_conv_16_sigm[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "skip_4 (Conv1D)                 (None, 196, 64)      4160        gated_activation_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_4 (Add)          (None, 196, 64)      0           skip_4[0][0]                     \n",
      "                                                                 residual_block_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_32_tanh (Conv1D)   (None, 196, 64)      8256        residual_block_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_32_sigm (Conv1D)   (None, 196, 64)      8256        residual_block_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_5 (Multiply)   (None, 196, 64)      0           dilated_conv_32_tanh[0][0]       \n",
      "                                                                 dilated_conv_32_sigm[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "skip_5 (Conv1D)                 (None, 196, 64)      4160        gated_activation_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_5 (Add)          (None, 196, 64)      0           skip_5[0][0]                     \n",
      "                                                                 residual_block_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_64_tanh (Conv1D)   (None, 196, 64)      8256        residual_block_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_64_sigm (Conv1D)   (None, 196, 64)      8256        residual_block_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_6 (Multiply)   (None, 196, 64)      0           dilated_conv_64_tanh[0][0]       \n",
      "                                                                 dilated_conv_64_sigm[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "skip_6 (Conv1D)                 (None, 196, 64)      4160        gated_activation_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_6 (Add)          (None, 196, 64)      0           skip_6[0][0]                     \n",
      "                                                                 residual_block_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_128_tanh (Conv1D)  (None, 196, 64)      8256        residual_block_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_128_sigm (Conv1D)  (None, 196, 64)      8256        residual_block_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_7 (Multiply)   (None, 196, 64)      0           dilated_conv_128_tanh[0][0]      \n",
      "                                                                 dilated_conv_128_sigm[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "skip_7 (Conv1D)                 (None, 196, 64)      4160        gated_activation_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "residual_block_7 (Add)          (None, 196, 64)      0           skip_7[0][0]                     \n",
      "                                                                 residual_block_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_256_tanh (Conv1D)  (None, 196, 64)      8256        residual_block_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_256_sigm (Conv1D)  (None, 196, 64)      8256        residual_block_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gated_activation_8 (Multiply)   (None, 196, 64)      0           dilated_conv_256_tanh[0][0]      \n",
      "                                                                 dilated_conv_256_sigm[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "skip_8 (Conv1D)                 (None, 196, 64)      4160        gated_activation_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "skip_connections (Add)          (None, 196, 64)      0           skip_1[0][0]                     \n",
      "                                                                 skip_2[0][0]                     \n",
      "                                                                 skip_3[0][0]                     \n",
      "                                                                 skip_4[0][0]                     \n",
      "                                                                 skip_5[0][0]                     \n",
      "                                                                 skip_6[0][0]                     \n",
      "                                                                 skip_7[0][0]                     \n",
      "                                                                 skip_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 196, 64)      0           skip_connections[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_5ms (Conv1D)               (None, 196, 64)      16448       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_500ms (Conv1D)             (None, 196, 340)     174420      conv_5ms[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_500ms_target_shape (Conv1D (None, 196, 340)     925140      conv_500ms[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "downsample_to_2Hz (AveragePooli (None, 25, 340)      0           conv_500ms_target_shape[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv1D)             (None, 25, 340)      693940      downsample_to_2Hz[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "final_pooling (GlobalAveragePoo (None, 340)          0           final_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "final_activation (Activation)   (None, 340)          0           final_pooling[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,975,772\n",
      "Trainable params: 1,975,772\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianing_sun/.local/lib/python3.5/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"fi..., inputs=Tensor(\"fe...)`\n"
     ]
    }
   ],
   "source": [
    "model = WaveNet(input_shape, output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(x,y): \n",
    "    return top_k_categorical_accuracy(x,y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    date = datetime.datetime.today().strftime('%H_%M_%m_%d')\n",
    "    weight_save_path = './model/stroke_wn_%s' % date + '.h5'\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(weight_save_path, monitor='val_loss',\n",
    "                                verbose=1, save_best_only=True, period=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.6, \n",
    "                                  patience=1, min_lr=1e-6, mode='auto')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "    callback = [checkpoint, early_stop, reduce_lr]\n",
    "    optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy', top_3_accuracy])\n",
    "    model.fit(x_train, y_train, \n",
    "              validation_data=(x_valid, y_valid),\n",
    "              batch_size=batch_size,\n",
    "              epochs=50,\n",
    "              callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, weight_path):\n",
    "    model = model.load_weights(weight_path)\n",
    "    result = model.evaluate(x_test, y_test, batch_size=4096)\n",
    "    print('Accuracy: %2.1f%%, Top 3 Accuracy %2.1f%%' % (100*lstm_results[1], 100*lstm_results[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearnReport(model, weight_path):\n",
    "    model = model.load_weights(weight_path)\n",
    "    test_cat = np.argmax(y_test, 1)\n",
    "    pred_y = model.predict(x_test, batch_size = 4096)\n",
    "    pred_cat = np.argmax(pred_y, 1)\n",
    "    plt.matshow(confusion_matrix(test_cat, pred_cat))\n",
    "    print(classification_report(test_cat, pred_cat, \n",
    "                            target_names = [x for x in word_encoder.classes_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 255000 samples, validate on 25500 samples\n",
      "Epoch 1/50\n",
      "255000/255000 [==============================] - 136s 534us/step - loss: 5.6313 - acc: 0.0096 - top_3_accuracy: 0.0276 - val_loss: 5.3416 - val_acc: 0.0235 - val_top_3_accuracy: 0.0578\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.34156, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 2/50\n",
      "255000/255000 [==============================] - 115s 449us/step - loss: 5.2100 - acc: 0.0308 - top_3_accuracy: 0.0737 - val_loss: 5.0912 - val_acc: 0.0472 - val_top_3_accuracy: 0.1025\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.34156 to 5.09117, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 3/50\n",
      "255000/255000 [==============================] - 115s 450us/step - loss: 4.9312 - acc: 0.0594 - top_3_accuracy: 0.1314 - val_loss: 4.7714 - val_acc: 0.0734 - val_top_3_accuracy: 0.1577\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.09117 to 4.77138, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 4/50\n",
      "255000/255000 [==============================] - 115s 450us/step - loss: 4.5967 - acc: 0.0928 - top_3_accuracy: 0.1930 - val_loss: 4.4809 - val_acc: 0.1070 - val_top_3_accuracy: 0.2142\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.77138 to 4.48087, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 5/50\n",
      "255000/255000 [==============================] - 115s 450us/step - loss: 4.3318 - acc: 0.1226 - top_3_accuracy: 0.2442 - val_loss: 4.2444 - val_acc: 0.1384 - val_top_3_accuracy: 0.2653\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.48087 to 4.24443, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 6/50\n",
      "255000/255000 [==============================] - 115s 449us/step - loss: 4.1138 - acc: 0.1516 - top_3_accuracy: 0.2906 - val_loss: 4.0539 - val_acc: 0.1620 - val_top_3_accuracy: 0.3077\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.24443 to 4.05387, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 7/50\n",
      "255000/255000 [==============================] - 115s 449us/step - loss: 3.9401 - acc: 0.1774 - top_3_accuracy: 0.3292 - val_loss: 3.9017 - val_acc: 0.1864 - val_top_3_accuracy: 0.3444\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.05387 to 3.90168, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 8/50\n",
      "255000/255000 [==============================] - 114s 448us/step - loss: 3.8051 - acc: 0.1983 - top_3_accuracy: 0.3579 - val_loss: 3.7793 - val_acc: 0.2071 - val_top_3_accuracy: 0.3696\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.90168 to 3.77932, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 9/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 3.6945 - acc: 0.2173 - top_3_accuracy: 0.3827 - val_loss: 3.6760 - val_acc: 0.2245 - val_top_3_accuracy: 0.3920\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.77932 to 3.67595, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 10/50\n",
      "255000/255000 [==============================] - 115s 449us/step - loss: 3.5983 - acc: 0.2335 - top_3_accuracy: 0.4040 - val_loss: 3.5941 - val_acc: 0.2400 - val_top_3_accuracy: 0.4087\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.67595 to 3.59412, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 11/50\n",
      "255000/255000 [==============================] - 115s 449us/step - loss: 3.5161 - acc: 0.2471 - top_3_accuracy: 0.4223 - val_loss: 3.5203 - val_acc: 0.2475 - val_top_3_accuracy: 0.4227\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.59412 to 3.52027, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 12/50\n",
      "255000/255000 [==============================] - 115s 450us/step - loss: 3.4442 - acc: 0.2594 - top_3_accuracy: 0.4387 - val_loss: 3.4779 - val_acc: 0.2554 - val_top_3_accuracy: 0.4365\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.52027 to 3.47794, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 13/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 3.3850 - acc: 0.2702 - top_3_accuracy: 0.4510 - val_loss: 3.4285 - val_acc: 0.2666 - val_top_3_accuracy: 0.4459\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.47794 to 3.42849, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 14/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 3.3270 - acc: 0.2800 - top_3_accuracy: 0.4636 - val_loss: 3.3485 - val_acc: 0.2795 - val_top_3_accuracy: 0.4640\n",
      "\n",
      "Epoch 00014: val_loss improved from 3.42849 to 3.34846, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 15/50\n",
      "255000/255000 [==============================] - 115s 449us/step - loss: 3.2680 - acc: 0.2904 - top_3_accuracy: 0.4769 - val_loss: 3.2865 - val_acc: 0.2885 - val_top_3_accuracy: 0.4747\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.34846 to 3.28652, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 16/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 3.2210 - acc: 0.2992 - top_3_accuracy: 0.4873 - val_loss: 3.2528 - val_acc: 0.2972 - val_top_3_accuracy: 0.4830\n",
      "\n",
      "Epoch 00016: val_loss improved from 3.28652 to 3.25282, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 17/50\n",
      "255000/255000 [==============================] - 115s 450us/step - loss: 3.1747 - acc: 0.3080 - top_3_accuracy: 0.4970 - val_loss: 3.2161 - val_acc: 0.3012 - val_top_3_accuracy: 0.4908\n",
      "\n",
      "Epoch 00017: val_loss improved from 3.25282 to 3.21615, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 18/50\n",
      "255000/255000 [==============================] - 115s 449us/step - loss: 3.1307 - acc: 0.3166 - top_3_accuracy: 0.5070 - val_loss: 3.1932 - val_acc: 0.3089 - val_top_3_accuracy: 0.4975\n",
      "\n",
      "Epoch 00018: val_loss improved from 3.21615 to 3.19315, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 19/50\n",
      "255000/255000 [==============================] - 114s 448us/step - loss: 3.0895 - acc: 0.3235 - top_3_accuracy: 0.5145 - val_loss: 3.1330 - val_acc: 0.3186 - val_top_3_accuracy: 0.5088\n",
      "\n",
      "Epoch 00019: val_loss improved from 3.19315 to 3.13304, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 20/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 3.0476 - acc: 0.3310 - top_3_accuracy: 0.5244 - val_loss: 3.0895 - val_acc: 0.3271 - val_top_3_accuracy: 0.5165\n",
      "\n",
      "Epoch 00020: val_loss improved from 3.13304 to 3.08945, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 21/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 3.0108 - acc: 0.3374 - top_3_accuracy: 0.5317 - val_loss: 3.0500 - val_acc: 0.3333 - val_top_3_accuracy: 0.5247\n",
      "\n",
      "Epoch 00021: val_loss improved from 3.08945 to 3.04998, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 22/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 2.9764 - acc: 0.3442 - top_3_accuracy: 0.5388 - val_loss: 3.0203 - val_acc: 0.3396 - val_top_3_accuracy: 0.5298\n",
      "\n",
      "Epoch 00022: val_loss improved from 3.04998 to 3.02028, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 23/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 2.9420 - acc: 0.3498 - top_3_accuracy: 0.5467 - val_loss: 2.9879 - val_acc: 0.3499 - val_top_3_accuracy: 0.5375\n",
      "\n",
      "Epoch 00023: val_loss improved from 3.02028 to 2.98791, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 24/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 2.9103 - acc: 0.3553 - top_3_accuracy: 0.5521 - val_loss: 2.9657 - val_acc: 0.3485 - val_top_3_accuracy: 0.5425\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.98791 to 2.96573, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 25/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 2.8783 - acc: 0.3611 - top_3_accuracy: 0.5595 - val_loss: 2.9385 - val_acc: 0.3555 - val_top_3_accuracy: 0.5480\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.96573 to 2.93852, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 26/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 2.8502 - acc: 0.3671 - top_3_accuracy: 0.5654 - val_loss: 2.9169 - val_acc: 0.3574 - val_top_3_accuracy: 0.5522\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.93852 to 2.91686, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 27/50\n",
      "255000/255000 [==============================] - 115s 449us/step - loss: 2.8204 - acc: 0.3723 - top_3_accuracy: 0.5720 - val_loss: 2.9136 - val_acc: 0.3570 - val_top_3_accuracy: 0.5520\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.91686 to 2.91359, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255000/255000 [==============================] - 115s 450us/step - loss: 2.7946 - acc: 0.3766 - top_3_accuracy: 0.5769 - val_loss: 2.8765 - val_acc: 0.3649 - val_top_3_accuracy: 0.5612\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.91359 to 2.87650, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 29/50\n",
      "255000/255000 [==============================] - 115s 450us/step - loss: 2.7677 - acc: 0.3825 - top_3_accuracy: 0.5817 - val_loss: 2.8356 - val_acc: 0.3755 - val_top_3_accuracy: 0.5698\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.87650 to 2.83560, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 30/50\n",
      "255000/255000 [==============================] - 115s 449us/step - loss: 2.7417 - acc: 0.3881 - top_3_accuracy: 0.5874 - val_loss: 2.8150 - val_acc: 0.3771 - val_top_3_accuracy: 0.5747\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.83560 to 2.81499, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 31/50\n",
      "255000/255000 [==============================] - 114s 448us/step - loss: 2.7168 - acc: 0.3918 - top_3_accuracy: 0.5926 - val_loss: 2.7886 - val_acc: 0.3805 - val_top_3_accuracy: 0.5785\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.81499 to 2.78857, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 32/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 2.6969 - acc: 0.3953 - top_3_accuracy: 0.5965 - val_loss: 2.7746 - val_acc: 0.3849 - val_top_3_accuracy: 0.5813\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.78857 to 2.77457, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 33/50\n",
      "255000/255000 [==============================] - 115s 449us/step - loss: 2.6719 - acc: 0.4005 - top_3_accuracy: 0.6014 - val_loss: 2.7402 - val_acc: 0.3915 - val_top_3_accuracy: 0.5902\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.77457 to 2.74020, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 34/50\n",
      "255000/255000 [==============================] - 114s 448us/step - loss: 2.6498 - acc: 0.4053 - top_3_accuracy: 0.6054 - val_loss: 2.7372 - val_acc: 0.3941 - val_top_3_accuracy: 0.5872\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.74020 to 2.73719, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 35/50\n",
      "255000/255000 [==============================] - 115s 450us/step - loss: 2.6329 - acc: 0.4080 - top_3_accuracy: 0.6084 - val_loss: 2.7132 - val_acc: 0.3969 - val_top_3_accuracy: 0.5955\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.73719 to 2.71322, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 36/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 2.6093 - acc: 0.4127 - top_3_accuracy: 0.6142 - val_loss: 2.6961 - val_acc: 0.3995 - val_top_3_accuracy: 0.5964\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.71322 to 2.69608, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 37/50\n",
      "255000/255000 [==============================] - 115s 449us/step - loss: 2.5933 - acc: 0.4150 - top_3_accuracy: 0.6169 - val_loss: 2.7060 - val_acc: 0.3969 - val_top_3_accuracy: 0.5941\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.69608\n",
      "Epoch 38/50\n",
      "255000/255000 [==============================] - 115s 449us/step - loss: 2.5684 - acc: 0.4210 - top_3_accuracy: 0.6229 - val_loss: 2.6697 - val_acc: 0.4069 - val_top_3_accuracy: 0.6027\n",
      "\n",
      "Epoch 00038: val_loss improved from 2.69608 to 2.66965, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 39/50\n",
      "255000/255000 [==============================] - 115s 449us/step - loss: 2.5558 - acc: 0.4225 - top_3_accuracy: 0.6244 - val_loss: 2.6525 - val_acc: 0.4105 - val_top_3_accuracy: 0.6063\n",
      "\n",
      "Epoch 00039: val_loss improved from 2.66965 to 2.65248, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 40/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 2.5385 - acc: 0.4268 - top_3_accuracy: 0.6282 - val_loss: 2.6337 - val_acc: 0.4117 - val_top_3_accuracy: 0.6102\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.65248 to 2.63369, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 41/50\n",
      "255000/255000 [==============================] - 114s 448us/step - loss: 2.5187 - acc: 0.4306 - top_3_accuracy: 0.6324 - val_loss: 2.6106 - val_acc: 0.4171 - val_top_3_accuracy: 0.6162\n",
      "\n",
      "Epoch 00041: val_loss improved from 2.63369 to 2.61065, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 42/50\n",
      "255000/255000 [==============================] - 115s 449us/step - loss: 2.5035 - acc: 0.4334 - top_3_accuracy: 0.6349 - val_loss: 2.6013 - val_acc: 0.4187 - val_top_3_accuracy: 0.6178\n",
      "\n",
      "Epoch 00042: val_loss improved from 2.61065 to 2.60130, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 43/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 2.4901 - acc: 0.4361 - top_3_accuracy: 0.6372 - val_loss: 2.5963 - val_acc: 0.4171 - val_top_3_accuracy: 0.6181\n",
      "\n",
      "Epoch 00043: val_loss improved from 2.60130 to 2.59633, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 44/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 2.4669 - acc: 0.4406 - top_3_accuracy: 0.6425 - val_loss: 2.5710 - val_acc: 0.4237 - val_top_3_accuracy: 0.6220\n",
      "\n",
      "Epoch 00044: val_loss improved from 2.59633 to 2.57101, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 45/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 2.4581 - acc: 0.4422 - top_3_accuracy: 0.6440 - val_loss: 2.5711 - val_acc: 0.4235 - val_top_3_accuracy: 0.6244\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.57101\n",
      "Epoch 46/50\n",
      "255000/255000 [==============================] - 114s 448us/step - loss: 2.4412 - acc: 0.4463 - top_3_accuracy: 0.6474 - val_loss: 2.5610 - val_acc: 0.4276 - val_top_3_accuracy: 0.6255\n",
      "\n",
      "Epoch 00046: val_loss improved from 2.57101 to 2.56100, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 47/50\n",
      "255000/255000 [==============================] - 115s 449us/step - loss: 2.4286 - acc: 0.4476 - top_3_accuracy: 0.6502 - val_loss: 2.5314 - val_acc: 0.4295 - val_top_3_accuracy: 0.6319\n",
      "\n",
      "Epoch 00047: val_loss improved from 2.56100 to 2.53138, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 48/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 2.4140 - acc: 0.4509 - top_3_accuracy: 0.6526 - val_loss: 2.5218 - val_acc: 0.4312 - val_top_3_accuracy: 0.6323\n",
      "\n",
      "Epoch 00048: val_loss improved from 2.53138 to 2.52176, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 49/50\n",
      "255000/255000 [==============================] - 114s 448us/step - loss: 2.3974 - acc: 0.4537 - top_3_accuracy: 0.6561 - val_loss: 2.5071 - val_acc: 0.4364 - val_top_3_accuracy: 0.6341\n",
      "\n",
      "Epoch 00049: val_loss improved from 2.52176 to 2.50708, saving model to ./model/stroke_wn_18_32_10_06.h5\n",
      "Epoch 50/50\n",
      "255000/255000 [==============================] - 114s 449us/step - loss: 2.3886 - acc: 0.4555 - top_3_accuracy: 0.6569 - val_loss: 2.4934 - val_acc: 0.4398 - val_top_3_accuracy: 0.6396\n",
      "\n",
      "Epoch 00050: val_loss improved from 2.50708 to 2.49338, saving model to ./model/stroke_wn_18_32_10_06.h5\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000/17000 [==============================] - 2s 102us/step\n",
      "Accuracy: 44.1%, Top 3 Accuracy 64.2%\n"
     ]
    }
   ],
   "source": [
    "# test \n",
    "weight_path = './model/stroke_wn_18_32_10_06.h5'\n",
    "model.load_weights(weight_path)\n",
    "wn_results = model.evaluate(x_test, y_test, batch_size = 4096)\n",
    "print('Accuracy: %2.1f%%, Top 3 Accuracy %2.1f%%' % (100*wn_results[1], 100*wn_results[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 255000 samples, validate on 25500 samples\n",
      "Epoch 1/50\n",
      "255000/255000 [==============================] - 115s 452us/step - loss: 2.4132 - acc: 0.4498 - top_3_accuracy: 0.6522 - val_loss: 2.4980 - val_acc: 0.4368 - val_top_3_accuracy: 0.6364\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.49796, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 2/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.3771 - acc: 0.4578 - top_3_accuracy: 0.6604 - val_loss: 2.4794 - val_acc: 0.4402 - val_top_3_accuracy: 0.6437\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.49796 to 2.47941, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 3/50\n",
      "255000/255000 [==============================] - 107s 421us/step - loss: 2.3638 - acc: 0.4594 - top_3_accuracy: 0.6624 - val_loss: 2.4665 - val_acc: 0.4434 - val_top_3_accuracy: 0.6435\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.47941 to 2.46653, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 4/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.3400 - acc: 0.4645 - top_3_accuracy: 0.6668 - val_loss: 2.4506 - val_acc: 0.4443 - val_top_3_accuracy: 0.6465\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.46653 to 2.45064, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 5/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.3269 - acc: 0.4667 - top_3_accuracy: 0.6690 - val_loss: 2.4449 - val_acc: 0.4489 - val_top_3_accuracy: 0.6491\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.45064 to 2.44485, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 6/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.3129 - acc: 0.4695 - top_3_accuracy: 0.6722 - val_loss: 2.4151 - val_acc: 0.4536 - val_top_3_accuracy: 0.6547\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.44485 to 2.41508, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 7/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.2938 - acc: 0.4745 - top_3_accuracy: 0.6754 - val_loss: 2.4202 - val_acc: 0.4497 - val_top_3_accuracy: 0.6530\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.41508\n",
      "Epoch 8/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.2516 - acc: 0.4831 - top_3_accuracy: 0.6843 - val_loss: 2.3756 - val_acc: 0.4600 - val_top_3_accuracy: 0.6631\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.41508 to 2.37557, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 9/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.2394 - acc: 0.4857 - top_3_accuracy: 0.6866 - val_loss: 2.3649 - val_acc: 0.4660 - val_top_3_accuracy: 0.6656\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.37557 to 2.36488, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 10/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.2294 - acc: 0.4880 - top_3_accuracy: 0.6880 - val_loss: 2.3579 - val_acc: 0.4687 - val_top_3_accuracy: 0.6665\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.36488 to 2.35794, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 11/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.2198 - acc: 0.4900 - top_3_accuracy: 0.6902 - val_loss: 2.3519 - val_acc: 0.4695 - val_top_3_accuracy: 0.6678\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.35794 to 2.35190, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 12/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.2113 - acc: 0.4911 - top_3_accuracy: 0.6914 - val_loss: 2.3476 - val_acc: 0.4668 - val_top_3_accuracy: 0.6692\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.35190 to 2.34761, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 13/50\n",
      "255000/255000 [==============================] - 107s 421us/step - loss: 2.2006 - acc: 0.4940 - top_3_accuracy: 0.6935 - val_loss: 2.3337 - val_acc: 0.4697 - val_top_3_accuracy: 0.6711\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.34761 to 2.33373, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 14/50\n",
      "255000/255000 [==============================] - 107s 421us/step - loss: 2.1909 - acc: 0.4956 - top_3_accuracy: 0.6950 - val_loss: 2.3233 - val_acc: 0.4734 - val_top_3_accuracy: 0.6740\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.33373 to 2.32331, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 15/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.1831 - acc: 0.4975 - top_3_accuracy: 0.6966 - val_loss: 2.3195 - val_acc: 0.4732 - val_top_3_accuracy: 0.6736\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.32331 to 2.31952, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 16/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.1732 - acc: 0.4996 - top_3_accuracy: 0.6988 - val_loss: 2.3262 - val_acc: 0.4721 - val_top_3_accuracy: 0.6720\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.31952\n",
      "Epoch 17/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.1471 - acc: 0.5049 - top_3_accuracy: 0.7034 - val_loss: 2.2892 - val_acc: 0.4816 - val_top_3_accuracy: 0.6830\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.31952 to 2.28916, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 18/50\n",
      "255000/255000 [==============================] - 107s 421us/step - loss: 2.1399 - acc: 0.5071 - top_3_accuracy: 0.7042 - val_loss: 2.2859 - val_acc: 0.4798 - val_top_3_accuracy: 0.6815\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.28916 to 2.28589, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 19/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.1331 - acc: 0.5076 - top_3_accuracy: 0.7059 - val_loss: 2.2830 - val_acc: 0.4831 - val_top_3_accuracy: 0.6804\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.28589 to 2.28302, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 20/50\n",
      "255000/255000 [==============================] - 107s 421us/step - loss: 2.1296 - acc: 0.5086 - top_3_accuracy: 0.7067 - val_loss: 2.2815 - val_acc: 0.4806 - val_top_3_accuracy: 0.6813\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.28302 to 2.28148, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 21/50\n",
      "255000/255000 [==============================] - 107s 421us/step - loss: 2.1240 - acc: 0.5100 - top_3_accuracy: 0.7071 - val_loss: 2.2749 - val_acc: 0.4827 - val_top_3_accuracy: 0.6837\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.28148 to 2.27486, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 22/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.1173 - acc: 0.5113 - top_3_accuracy: 0.7091 - val_loss: 2.2698 - val_acc: 0.4832 - val_top_3_accuracy: 0.6831\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.27486 to 2.26984, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 23/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.1130 - acc: 0.5124 - top_3_accuracy: 0.7098 - val_loss: 2.2655 - val_acc: 0.4838 - val_top_3_accuracy: 0.6845\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.26984 to 2.26546, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 24/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.1082 - acc: 0.5130 - top_3_accuracy: 0.7105 - val_loss: 2.2605 - val_acc: 0.4843 - val_top_3_accuracy: 0.6872\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.26546 to 2.26051, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 25/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.1033 - acc: 0.5138 - top_3_accuracy: 0.7115 - val_loss: 2.2651 - val_acc: 0.4827 - val_top_3_accuracy: 0.6845\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.26051\n",
      "Epoch 26/50\n",
      "255000/255000 [==============================] - 107s 421us/step - loss: 2.0853 - acc: 0.5185 - top_3_accuracy: 0.7149 - val_loss: 2.2479 - val_acc: 0.4891 - val_top_3_accuracy: 0.6901\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.26051 to 2.24788, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 27/50\n",
      "255000/255000 [==============================] - 107s 421us/step - loss: 2.0802 - acc: 0.5201 - top_3_accuracy: 0.7158 - val_loss: 2.2430 - val_acc: 0.4893 - val_top_3_accuracy: 0.6885\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.24788 to 2.24298, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 28/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.0777 - acc: 0.5198 - top_3_accuracy: 0.7159 - val_loss: 2.2400 - val_acc: 0.4886 - val_top_3_accuracy: 0.6899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: val_loss improved from 2.24298 to 2.23995, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 29/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.0747 - acc: 0.5210 - top_3_accuracy: 0.7162 - val_loss: 2.2409 - val_acc: 0.4897 - val_top_3_accuracy: 0.6901\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.23995\n",
      "Epoch 30/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.0641 - acc: 0.5233 - top_3_accuracy: 0.7191 - val_loss: 2.2312 - val_acc: 0.4933 - val_top_3_accuracy: 0.6915\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.23995 to 2.23121, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 31/50\n",
      "255000/255000 [==============================] - 107s 421us/step - loss: 2.0607 - acc: 0.5241 - top_3_accuracy: 0.7191 - val_loss: 2.2308 - val_acc: 0.4938 - val_top_3_accuracy: 0.6927\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.23121 to 2.23082, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 32/50\n",
      "255000/255000 [==============================] - 107s 421us/step - loss: 2.0596 - acc: 0.5249 - top_3_accuracy: 0.7190 - val_loss: 2.2273 - val_acc: 0.4933 - val_top_3_accuracy: 0.6925\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.23082 to 2.22732, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 33/50\n",
      "255000/255000 [==============================] - 107s 420us/step - loss: 2.0577 - acc: 0.5246 - top_3_accuracy: 0.7198 - val_loss: 2.2270 - val_acc: 0.4928 - val_top_3_accuracy: 0.6935\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.22732 to 2.22701, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 34/50\n",
      "255000/255000 [==============================] - 107s 421us/step - loss: 2.0549 - acc: 0.5255 - top_3_accuracy: 0.7202 - val_loss: 2.2248 - val_acc: 0.4948 - val_top_3_accuracy: 0.6928\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.22701 to 2.22482, saving model to ./model/stroke_wn_20_11_10_06.h5\n",
      "Epoch 35/50\n",
      " 69632/255000 [=======>......................] - ETA: 1:16 - loss: 2.0528 - acc: 0.5261 - top_3_accuracy: 0.7197"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-544c2698be46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fine-tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-cc983d9158ef>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     18\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m               callbacks=callback)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fine-tuning\n",
    "model.load_weights(weight_path)\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
